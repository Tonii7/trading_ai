# ==============================================
# src/trading_ai/analytics/statistics.py
# –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä—ã–Ω–∫–æ–≤
# (–≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å, –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã, –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏, –∞–Ω–æ–º–∞–ª–∏–∏, –±—ç–∫—Ç–µ—Å—Ç)
# ==============================================

from __future__ import annotations

import os
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
from scipy import stats

# TA-–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (–ø–æ –∂–µ–ª–∞–Ω–∏—é). –ù—É–∂–Ω–æ: pip install pandas-ta
try:
    import pandas_ta as ta
except ImportError:
    ta = None


# ---------- –ë–∞–∑–æ–≤—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã ----------

@dataclass
class ReturnStats:
    total_return: float
    annual_return: float
    annual_vol: float
    sharpe: float


@dataclass
class BacktestResult:
    initial_balance: float
    final_balance: float
    total_return_pct: float
    max_drawdown_pct: float
    equity_curve: pd.Series


# ---------- –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ ----------

def ensure_datetime_index(df: pd.DataFrame) -> pd.DataFrame:
    """–£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∏–Ω–¥–µ–∫—Å ‚Äî —ç—Ç–æ datetime (–¥–ª—è —Ä–µ—Å–µ–º–ø–ª–∏–Ω–≥–∞ –∏ —Ç.–ø.)."""
    if not isinstance(df.index, pd.DatetimeIndex):
        if "Date" in df.columns:
            df = df.copy()
            df["Date"] = pd.to_datetime(df["Date"])
            df = df.set_index("Date")
        else:
            raise ValueError("DataFrame must have DatetimeIndex or a 'Date' column.")
    return df


# ---------- 1. –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –∏ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ ----------

def calc_return_stats(
    df: pd.DataFrame,
    price_col: str = "Close",
    periods_per_year: int = 252
) -> ReturnStats:
    """
    –°—á–∏—Ç–∞–µ—Ç –±–∞–∑–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º:
      - –æ–±—â–∏–π –¥–æ—Ö–æ–¥
      - –≥–æ–¥–æ–≤–æ–π –¥–æ—Ö–æ–¥
      - –≥–æ–¥–æ–≤–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
      - Sharpe ratio (–±–µ–∑ –±–µ–∑—Ä–∏—Å–∫–æ–≤–æ–π —Å—Ç–∞–≤–∫–∏)
    """
    df = ensure_datetime_index(df)
    prices = df[price_col].dropna()

    rets = prices.pct_change().dropna()
    if len(rets) == 0:
        return ReturnStats(0.0, 0.0, 0.0, 0.0)

    total_return = (prices.iloc[-1] / prices.iloc[0] - 1.0) * 100.0
    avg_ret = rets.mean()
    vol = rets.std()

    annual_return = (1 + avg_ret) ** periods_per_year - 1
    annual_vol = vol * np.sqrt(periods_per_year)
    sharpe = annual_return / annual_vol if annual_vol != 0 else 0.0

    return ReturnStats(
        total_return=round(total_return, 2),
        annual_return=round(annual_return * 100.0, 2),
        annual_vol=round(annual_vol * 100.0, 2),
        sharpe=round(sharpe, 2),
    )


def calc_rolling_volatility(
    df: pd.DataFrame,
    price_col: str = "Close",
    window: int = 14,
    periods_per_year: int = 252
) -> pd.Series:
    """
    –°–∫–æ–ª—å–∑—è—â–∞—è –≥–æ–¥–æ–≤–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –ø–æ –æ–∫–Ω—É.
    """
    df = ensure_datetime_index(df)
    rets = df[price_col].pct_change()
    rolling_std = rets.rolling(window).std()
    return rolling_std * np.sqrt(periods_per_year)


# ---------- 2. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã ----------

def add_basic_indicators(
    df: pd.DataFrame,
    price_col: str = "Close",
    volume_col: str = "Volume"
) -> pd.DataFrame:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç –±–∞–∑–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã: SMA, EMA, RSI, MACD, Bollinger Bands.
    –¢—Ä–µ–±—É–µ—Ç pandas-ta. –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç df.
    """
    df = ensure_datetime_index(df)
    df = df.copy()

    if ta is None:
        # –ë–µ–∑ pandas_ta –ø—Ä–æ—Å—Ç–æ –≤–µ—Ä–Ω—ë–º –∏—Å—Ö–æ–¥–Ω—ã–π df
        return df

    close = df[price_col]

    df["SMA_50"] = close.rolling(50).mean()
    df["SMA_200"] = close.rolling(200).mean()

    df["EMA_20"] = close.ewm(span=20, adjust=False).mean()

    df["RSI_14"] = ta.rsi(close, length=14)
    macd_res = ta.macd(close, fast=12, slow=26, signal=9)
    if macd_res is not None and not macd_res.empty:
        df["MACD"] = macd_res.iloc[:, 0]
        df["MACD_signal"] = macd_res.iloc[:, 1]

    bb = ta.bbands(close, length=20, std=2)
    if bb is not None and not bb.empty:
        df["BB_up"] = bb.iloc[:, 0]
        df["BB_mid"] = bb.iloc[:, 1]
        df["BB_low"] = bb.iloc[:, 2]

    if volume_col in df.columns:
        df["Vol_MA_20"] = df[volume_col].rolling(20).mean()

    return df


# ---------- 3. –ê–Ω–æ–º–∞–ª–∏–∏ –æ–±—ä—ë–º–∞ –∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ ----------

def detect_volume_spikes(
    df: pd.DataFrame,
    volume_col: str = "Volume",
    window: int = 30,
    z_threshold: float = 3.0
) -> pd.DataFrame:
    """
    –ù–∞—Ö–æ–¥–∏—Ç —Å–≤–µ—á–∏ —Å –∞–Ω–æ–º–∞–ª—å–Ω–æ –≤—ã—Å–æ–∫–∏–º –æ–±—ä—ë–º–æ–º –ø–æ z-score.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç df —Å –∫–æ–ª–æ–Ω–∫–æ–π volume_zscore –∏ —Ç–æ–ª—å–∫–æ –∞–Ω–æ–º–∞–ª—å–Ω—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏.
    """
    df = ensure_datetime_index(df)
    df = df.copy()

    if volume_col not in df.columns:
        raise ValueError(f"Column '{volume_col}' not found in DataFrame.")

    rolling_mean = df[volume_col].rolling(window).mean()
    rolling_std = df[volume_col].rolling(window).std()

    df["volume_zscore"] = (df[volume_col] - rolling_mean) / rolling_std
    anomalies = df[df["volume_zscore"] > z_threshold]
    return anomalies


def detect_volatility_shift(
    df: pd.DataFrame,
    price_col: str = "Close",
    recent_window: int = 20,
    past_window: int = 100,
    alpha: float = 0.05
) -> Tuple[float, float]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∏–∑–º–µ–Ω–∏–ª–∞—Å—å –ª–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º–æ (t-test)
    –º–µ–∂–¥—É –Ω–µ–¥–∞–≤–Ω–∏–º –ø–µ—Ä–∏–æ–¥–æ–º –∏ —Å—Ç–∞—Ä—ã–º.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (t_stat, p_value).
    """
    df = ensure_datetime_index(df)
    rets = df[price_col].pct_change().dropna()

    if len(rets) < recent_window + past_window:
        return 0.0, 1.0

    recent = rets.tail(recent_window)
    past = rets.head(past_window)

    t_stat, p_val = stats.levene(recent, past)  # –∫—Ä–∏—Ç–µ—Ä–∏–π –õ–µ–≤–µ–Ω–∞ –ø–æ –¥–∏—Å–ø–µ—Ä—Å–∏–∏
    # p_val < alpha => –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –∏–∑–º–µ–Ω–∏–ª–∞—Å—å –∑–Ω–∞—á–∏–º–æ
    return float(t_stat), float(p_val)


# ---------- 4. –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –∏ –∫—Ä–æ—Å—Å-–∞–∫—Ç–∏–≤—ã ----------

def correlation_matrix_from_dict(
    price_series_dict: Dict[str, pd.Series]
) -> pd.DataFrame:
    """
    –ò–∑ —Å–ª–æ–≤–∞—Ä—è {–∏–º—è_–∞–∫—Ç–∏–≤–∞: Series —Ü–µ–Ω} —Å—Ç—Ä–æ–∏—Ç –º–∞—Ç—Ä–∏—Ü—É –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –ø–æ –¥–Ω–µ–≤–Ω—ã–º –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º.
    """
    df = pd.DataFrame(price_series_dict)
    # –°—á–∏—Ç–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
    returns = df.pct_change().dropna()
    return returns.corr()


# ---------- 5. –ü—Ä–æ—Å—Ç–µ–π—à–∏–π –±—ç–∫—Ç–µ—Å—Ç –ø–æ —Å–∏–≥–Ω–∞–ª–∞–º ----------

def simple_signal_backtest(
    df: pd.DataFrame,
    signal_col: str,
    price_col: str = "Close",
    initial_balance: float = 100_000.0,
    fee_per_trade: float = 0.0,
) -> BacktestResult:
    """
    –ü—Ä–æ—Å—Ç–µ–π—à–∏–π –±—ç–∫—Ç–µ—Å—Ç: —Å–∏–≥–Ω–∞–ª –≤ –∫–æ–ª–æ–Ω–∫–µ signal_col:
      +1 = long, 0 = –≤–Ω–µ —Ä—ã–Ω–∫–∞, -1 = —à–æ—Ä—Ç (–ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏).
    –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –≤–µ—Å—å –∫–∞–ø–∏—Ç–∞–ª –≤–∫–ª–∞–¥—ã–≤–∞–µ—Ç—Å—è –ø–æ —Å–∏–≥–Ω–∞–ª—É.
    """
    df = ensure_datetime_index(df)
    df = df.copy().dropna(subset=[price_col, signal_col])

    prices = df[price_col]
    signals = df[signal_col]

    rets = prices.pct_change().fillna(0.0)

    # –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: –ø–æ–∑–∏—Ü–∏—è * –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
    strat_rets = signals.shift(1).fillna(0.0) * rets  # –≤—Ö–æ–¥–∏–º –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–π —Å–≤–µ—á–µ

    # –£—á—ë—Ç –∫–æ–º–∏—Å—Å–∏–π: –µ—Å–ª–∏ —Å–∏–≥–Ω–∞–ª –º–µ–Ω—è–µ—Ç—Å—è, –±–µ—Ä—ë–º –∫–æ–º–∏—Å—Å–∏—é
    if fee_per_trade > 0.0:
        trades = (signals != signals.shift(1)).astype(float)
        fee_ret = trades * (fee_per_trade / initial_balance) * -1.0
        strat_rets = strat_rets + fee_ret

    equity = (1 + strat_rets).cumprod() * initial_balance

    final_balance = float(equity.iloc[-1])
    total_return_pct = (final_balance / initial_balance - 1.0) * 100.0

    # max drawdown
    roll_max = equity.cummax()
    drawdown = equity / roll_max - 1.0
    max_drawdown_pct = float(drawdown.min() * 100.0)

    return BacktestResult(
        initial_balance=initial_balance,
        final_balance=round(final_balance, 2),
        total_return_pct=round(total_return_pct, 2),
        max_drawdown_pct=round(max_drawdown_pct, 2),
        equity_curve=equity,
    )


# ---------- 6. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∑—é–º–µ ----------

def summarize_asset(
    name: str,
    df: pd.DataFrame,
    price_col: str = "Close",
    volume_col: str = "Volume"
) -> str:
    """
    –î–µ–ª–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Ä–µ–∑—é–º–µ –ø–æ –æ–¥–Ω–æ–º—É –∞–∫—Ç–∏–≤—É:
    - —Ç–µ–∫—É—â–∞—è —Ü–µ–Ω–∞
    - –≥–æ–¥–æ–≤–∞—è –≤–æ–ª–∞
    - –±–∞–∑–æ–≤–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
    - –µ—Å—Ç—å –ª–∏ –≤—Å–ø–ª–µ—Å–∫–∏ –æ–±—ä—ë–º–∞
    """
    df = ensure_datetime_index(df)
    df = df.dropna(subset=[price_col]).copy()

    stats_ret = calc_return_stats(df, price_col=price_col)

    vol_series = calc_rolling_volatility(df, price_col=price_col)
    last_vol = float(vol_series.dropna().iloc[-1]) * 100.0 if not vol_series.dropna().empty else 0.0

    txt = [f"üìä {name} summary:"]
    txt.append(f"- Current price: {df[price_col].iloc[-1]:.2f}")
    txt.append(f"- Total return: {stats_ret.total_return:.2f}%")
    txt.append(f"- Annual return: {stats_ret.annual_return:.2f}%")
    txt.append(f"- Annual volatility: {stats_ret.annual_vol:.2f}%")
    txt.append(f"- Sharpe (approx): {stats_ret.sharpe:.2f}")
    txt.append(f"- Latest rolling volatility (14d): {last_vol:.2f}%")

    if volume_col in df.columns:
        anomalies = detect_volume_spikes(df, volume_col=volume_col)
        if not anomalies.empty:
            last_spike_date = anomalies.index[-1].date()
            txt.append(f"- Recent volume spike detected on: {last_spike_date}")
        else:
            txt.append("- No strong volume spikes in recent window.")

    return "\n".join(txt)


if __name__ == "__main__":
    # –ü—Ä–∏–º–∏—Ç–∏–≤–Ω—ã–π —Ç–µ—Å—Ç –Ω–∞ —Å–ª—É—á–∞–π–Ω–æ–º —Ä—è–¥–µ (–¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏, —á—Ç–æ –º–æ–¥—É–ª—å –Ω–µ –ø–∞–¥–∞–µ—Ç)
    dates = pd.date_range("2024-01-01", periods=200, freq="D")
    prices = pd.Series(np.cumsum(np.random.randn(200)) + 100.0, index=dates)
    volumes = pd.Series(np.random.randint(100, 1000, size=200), index=dates)
    df_test = pd.DataFrame({"Close": prices, "Volume": volumes})

    print("=== Return stats test ===")
    rs = calc_return_stats(df_test)
    print(rs)

    print("\n=== Volume anomalies test ===")
    print(detect_volume_spikes(df_test).tail())

    print("\n=== Summary test ===")
    print(summarize_asset("TEST", df_test))
